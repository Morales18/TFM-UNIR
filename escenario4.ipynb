{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d27a6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021090561750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/stepWARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021090561750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.666667   0.678571  0.844444  0.752475  0.666667\n",
      "1  0.573333   0.622642  0.733333  0.673469  0.618519\n",
      "2  0.626667   0.644068  0.844444  0.730769  0.563704\n",
      "3  0.560000   0.603448  0.777778  0.679612  0.579259\n",
      "4  0.773333   0.773585  0.891304  0.828283  0.742879\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.6400     0.6645  0.8183  0.7329  0.6342\n",
      "std      0.0859     0.0671  0.0624  0.0630  0.0726\n",
      "min      0.5600     0.6034  0.7333  0.6735  0.5637\n",
      "25%      0.5733     0.6226  0.7778  0.6796  0.5793\n",
      "50%      0.6267     0.6441  0.8444  0.7308  0.6185\n",
      "75%      0.6667     0.6786  0.8444  0.7525  0.6667\n",
      "max      0.7733     0.7736  0.8913  0.8283  0.7429\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# === CARGAR LOS DATOS ===\n",
    "df_reales = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sinteticos = pd.read_excel(\"datos_sinteticos_finales.xlsx\")\n",
    "\n",
    "# Seleccionar subconjuntos\n",
    "df_reales_esc4 = df_reales.sample(n=75, random_state=42)\n",
    "df_sinteticos_esc4 = df_sinteticos.sample(n=300, random_state=42)\n",
    "\n",
    "# Unir ambos conjuntos\n",
    "df_escenario4 = pd.concat([df_reales_esc4, df_sinteticos_esc4], ignore_index=True)\n",
    "\n",
    "# Codificar variables categóricas\n",
    "df_escenario4 = pd.get_dummies(df_escenario4, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# Eliminar columna de texto si existe\n",
    "if 'Evolucion Final' in df_escenario4.columns:\n",
    "    df_escenario4.drop(columns=['Evolucion Final'], inplace=True)\n",
    "\n",
    "# === SEPARAR VARIABLES ===\n",
    "X = df_escenario4.drop(columns='target')\n",
    "y = df_escenario4['target']\n",
    "\n",
    "# === MODELO Y VALIDACIÓN ===\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "resultados = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=8,\n",
    "              callbacks=[es], verbose=0)\n",
    "\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c8d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PARA QUE LOS RESULTADOS SEAN REPRODUCIBLES \n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Establecer todas las semillas\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Forzar comportamiento determinista en TensorFlow (puede hacer más lento el entrenamiento)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f184404a",
   "metadata": {},
   "source": [
    "Incluso con esto, en algunas configuraciones hardware (especialmente si usas GPU y ciertas versiones de TensorFlow), puede seguir habiendo pequeñas variaciones debido a operaciones no deterministas. Pero en CPU o con determinismo habilitado, los resultados deberían ser idénticos en cada ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b650bca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.640000   0.655172  0.844444  0.737864  0.605185\n",
      "1  0.693333   0.683333  0.911111  0.780952  0.716296\n",
      "2  0.613333   0.633333  0.844444  0.723810  0.585926\n",
      "3  0.586667   0.616667  0.822222  0.704762  0.517778\n",
      "4  0.546667   0.607143  0.739130  0.666667  0.479760\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.6160     0.6391  0.8323  0.7228  0.5810\n",
      "std      0.0553     0.0307  0.0618  0.0421  0.0911\n",
      "min      0.5467     0.6071  0.7391  0.6667  0.4798\n",
      "25%      0.5867     0.6167  0.8222  0.7048  0.5178\n",
      "50%      0.6133     0.6333  0.8444  0.7238  0.5859\n",
      "75%      0.6400     0.6552  0.8444  0.7379  0.6052\n",
      "max      0.6933     0.6833  0.9111  0.7810  0.7163\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# === CARGAR LOS DATOS ===\n",
    "df_reales = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sinteticos = pd.read_excel(\"datos_sinteticos_finales.xlsx\")\n",
    "\n",
    "# Seleccionar subconjuntos\n",
    "df_reales_esc4 = df_reales.sample(n=75, random_state=42)\n",
    "df_sinteticos_esc4 = df_sinteticos.sample(n=300, random_state=42)\n",
    "\n",
    "# Unir ambos conjuntos\n",
    "df_escenario4 = pd.concat([df_reales_esc4, df_sinteticos_esc4], ignore_index=True)\n",
    "\n",
    "# Codificar variables categóricas\n",
    "df_escenario4 = pd.get_dummies(df_escenario4, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# Eliminar columna de texto si existe\n",
    "if 'Evolucion Final' in df_escenario4.columns:\n",
    "    df_escenario4.drop(columns=['Evolucion Final'], inplace=True)\n",
    "\n",
    "# === SEPARAR VARIABLES ===\n",
    "X = df_escenario4.drop(columns='target')\n",
    "y = df_escenario4['target']\n",
    "\n",
    "# === MODELO Y VALIDACIÓN ===\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "resultados = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=8,\n",
    "              callbacks=[es], verbose=0)\n",
    "\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566471a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Resultados por fold:\n",
      "    accuracy  precision  recall      f1     auc\n",
      "0    0.6267     0.6552  0.8261  0.7308  0.6522\n",
      "1    0.6133     0.6538  0.7556  0.7010  0.6415\n",
      "2    0.6133     0.6333  0.8444  0.7238  0.5504\n",
      "3    0.5867     0.6129  0.8444  0.7103  0.5504\n",
      "4    0.6667     0.6923  0.8000  0.7423  0.6578\n",
      "\n",
      "Resumen estadístico:\n",
      "        accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.6213     0.6495  0.8141  0.7216  0.6104\n",
      "std      0.0292     0.0295  0.0375  0.0163  0.0551\n",
      "min      0.5867     0.6129  0.7556  0.7010  0.5504\n",
      "25%      0.6133     0.6333  0.8000  0.7103  0.5504\n",
      "50%      0.6133     0.6538  0.8261  0.7238  0.6415\n",
      "75%      0.6267     0.6552  0.8444  0.7308  0.6522\n",
      "max      0.6667     0.6923  0.8444  0.7423  0.6578\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ================================\n",
    "# Controlar aleatoriedad global\n",
    "# ================================\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# ====================================\n",
    "# Cargar y preparar datasets\n",
    "# ====================================\n",
    "df_reales = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sinteticos = pd.read_excel(\"datos_sinteticos_finales.xlsx\")\n",
    "\n",
    "# Seleccionar 300 registros sintéticos aleatorios (si hay suficientes)\n",
    "df_sinteticos_muestra = df_sinteticos.sample(n=300, random_state=SEED)\n",
    "\n",
    "# Unificar datos\n",
    "df_total = pd.concat([df_reales, df_sinteticos_muestra], ignore_index=True)\n",
    "\n",
    "# Codificar variables categóricas\n",
    "df_total = pd.get_dummies(df_total, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# Eliminar variable textual\n",
    "if 'Evolucion Final' in df_total.columns:\n",
    "    df_total.drop(columns=['Evolucion Final'], inplace=True)\n",
    "\n",
    "# Separar variables\n",
    "X = df_total.drop(columns=['target'])\n",
    "y = df_total['target']\n",
    "\n",
    "# ====================================\n",
    "# Validación cruzada\n",
    "# ====================================\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "resultados = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Escalado\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Modelo base\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=16,\n",
    "              callbacks=[es], verbose=0)\n",
    "\n",
    "    # Evaluación\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# ====================================\n",
    "# Mostrar resultados\n",
    "# ====================================\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(\"\\nResultados por fold:\\n\", df_resultados.round(4))\n",
    "print(\"\\nResumen estadístico:\\n\", df_resultados.describe().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6bf49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
