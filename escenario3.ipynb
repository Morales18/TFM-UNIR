{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a224d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Dataset reales imputados ---\n",
    "df_reales = pd.read_excel(\"dataset_resultado_categorizado.xlsx\")\n",
    "\n",
    "# Imputar valores numéricos con la mediana\n",
    "df_reales_imputado = df_reales.copy()\n",
    "for col in df_reales_imputado.select_dtypes(include=[np.number]).columns:\n",
    "    df_reales_imputado[col] = df_reales_imputado[col].fillna(df_reales_imputado[col].median())\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "df_reales_imputado = df_reales_imputado.loc[:, ~df_reales_imputado.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Crear columna target\n",
    "df_reales_imputado['target'] = df_reales_imputado['Evolucion Final'].apply(lambda x: 1 if x != 'Nada' else 0)\n",
    "\n",
    "# Guardar el dataset limpio\n",
    "df_reales_imputado.to_excel(\"dataset_reales_imputados.xlsx\", index=False)\n",
    "\n",
    "\n",
    "# --- Dataset sintéticos ---\n",
    "df_sinteticos = pd.read_excel(\"datos_sinteticos_CTGAN_solo_positivos.xlsx\")\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "df_sinteticos = df_sinteticos.loc[:, ~df_sinteticos.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Crear columna target\n",
    "df_sinteticos['target'] = df_sinteticos['Evolucion Final'].apply(lambda x: 1 if x != 'Nada' else 0)\n",
    "\n",
    "# Guardar el dataset limpio\n",
    "df_sinteticos.to_excel(\"datos_sinteticos_finales.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2638377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.595174   0.608069  0.933628  0.736475  0.532298\n",
      "1  0.576408   0.611842  0.823009  0.701887  0.533412\n",
      "2  0.600536   0.621451  0.871681  0.725599  0.528445\n",
      "3  0.568365   0.606667  0.808889  0.693333  0.562673\n",
      "4  0.621984   0.618644  0.973333  0.756477  0.527477\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.5925     0.6133  0.8821  0.7228  0.5369\n",
      "std      0.0211     0.0065  0.0706  0.0257  0.0146\n",
      "min      0.5684     0.6067  0.8089  0.6933  0.5275\n",
      "25%      0.5764     0.6081  0.8230  0.7019  0.5284\n",
      "50%      0.5952     0.6118  0.8717  0.7256  0.5323\n",
      "75%      0.6005     0.6186  0.9336  0.7365  0.5334\n",
      "max      0.6220     0.6215  0.9733  0.7565  0.5627\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cargar los datasets preparados\n",
    "df_reales = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sinteticos = pd.read_excel(\"datos_sinteticos_finales.xlsx\")\n",
    "\n",
    "# Unificar datasets\n",
    "df_total = pd.concat([df_reales, df_sinteticos], ignore_index=True)\n",
    "\n",
    "# Codificación one-hot\n",
    "df_total = pd.get_dummies(df_total, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# Eliminar columna de texto no necesaria\n",
    "if 'Evolucion Final' in df_total.columns:\n",
    "    df_total.drop(columns=['Evolucion Final'], inplace=True)\n",
    "\n",
    "# Separar X e y\n",
    "X = df_total.drop(columns='target')\n",
    "y = df_total['target']\n",
    "\n",
    "# Validación cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "resultados = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=8, callbacks=[es], verbose=0)\n",
    "\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f16bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.597855   0.607345  0.951327  0.741379  0.506983\n",
      "1  0.613941   0.620588  0.933628  0.745583  0.542141\n",
      "2  0.616622   0.635179  0.862832  0.731707  0.577539\n",
      "3  0.597855   0.601078  0.991111  0.748322  0.574024\n",
      "4  0.611260   0.611111  0.977778  0.752137  0.560751\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.6075     0.6151  0.9433  0.7438  0.5523\n",
      "std      0.0090     0.0133  0.0503  0.0078  0.0289\n",
      "min      0.5979     0.6011  0.8628  0.7317  0.5070\n",
      "25%      0.5979     0.6073  0.9336  0.7414  0.5421\n",
      "50%      0.6113     0.6111  0.9513  0.7456  0.5608\n",
      "75%      0.6139     0.6206  0.9778  0.7483  0.5740\n",
      "max      0.6166     0.6352  0.9911  0.7521  0.5775\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cargar los datasets preparados\n",
    "df_reales = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sinteticos = pd.read_excel(\"datos_sinteticos_finales.xlsx\")\n",
    "\n",
    "# Unificar los datos\n",
    "df_total = pd.concat([df_reales, df_sinteticos], ignore_index=True)\n",
    "\n",
    "# One-hot encoding (por si acaso)\n",
    "df_total = pd.get_dummies(df_total, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# Variables predictoras y objetivo\n",
    "X = df_total.drop(columns=['Evolucion Final', 'target'])\n",
    "y = df_total['target']\n",
    "\n",
    "# Validación cruzada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "resultados = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Modelo profundo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=8, callbacks=[es], verbose=0)\n",
    "\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a6ff61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.592493   0.614198  0.880531  0.723636  0.506833\n",
      "1  0.589812   0.610272  0.893805  0.725314  0.505840\n",
      "2  0.576408   0.612583  0.818584  0.700758  0.574409\n",
      "3  0.611260   0.621212  0.911111  0.738739  0.601021\n",
      "4  0.533512   0.597701  0.693333  0.641975  0.492342\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.5807     0.6112  0.8395  0.7061  0.5361\n",
      "std      0.0292     0.0086  0.0888  0.0383  0.0484\n",
      "min      0.5335     0.5977  0.6933  0.6420  0.4923\n",
      "25%      0.5764     0.6103  0.8186  0.7008  0.5058\n",
      "50%      0.5898     0.6126  0.8805  0.7236  0.5068\n",
      "75%      0.5925     0.6142  0.8938  0.7253  0.5744\n",
      "max      0.6113     0.6212  0.9111  0.7387  0.6010\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cargar los datasets ya preparados\n",
    "df_reales = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sinteticos = pd.read_excel(\"datos_sinteticos_finales.xlsx\")\n",
    "\n",
    "# Unir ambos datasets\n",
    "df_total = pd.concat([df_reales, df_sinteticos], ignore_index=True)\n",
    "\n",
    "# Codificar variables categóricas si no lo están\n",
    "df_total = pd.get_dummies(df_total, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# Separar variables predictoras y objetivo\n",
    "X = df_total.drop(columns=['Evolucion Final', 'target'])\n",
    "y = df_total['target']\n",
    "\n",
    "# Validación cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "resultados = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Escalado de características\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Arquitectura más ligera\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Entrenamiento\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=16, callbacks=[es], verbose=0)\n",
    "\n",
    "    # Predicción y evaluación\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994e46e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000010F0573D0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "WARNING:tensorflow:6 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000010F0573D040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.733333   0.708333  0.944444  0.809524  0.726852\n",
      "1  0.633333   0.652174  0.833333  0.731707  0.587963\n",
      "2  0.833333   0.842105  0.888889  0.864865  0.800926\n",
      "3  0.800000   0.809524  0.894737  0.850000  0.779904\n",
      "4  0.633333   0.653846  0.894737  0.755556  0.736842\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.7267     0.7332  0.8912  0.8023  0.7265\n",
      "std      0.0925     0.0883  0.0394  0.0579  0.0832\n",
      "min      0.6333     0.6522  0.8333  0.7317  0.5880\n",
      "25%      0.6333     0.6538  0.8889  0.7556  0.7269\n",
      "50%      0.7333     0.7083  0.8947  0.8095  0.7368\n",
      "75%      0.8000     0.8095  0.8947  0.8500  0.7799\n",
      "max      0.8333     0.8421  0.9444  0.8649  0.8009\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 1. Cargar datasets\n",
    "df_reales = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sinteticos = pd.read_excel(\"datos_sinteticos_finales.xlsx\")\n",
    "\n",
    "# 2. Seleccionar 75 reales y 75 sintéticos\n",
    "df_reales_75 = df_reales.sample(n=75, random_state=42)\n",
    "df_sinteticos_75 = df_sinteticos.sample(n=75, random_state=42)\n",
    "\n",
    "# 3. Concatenar ambos datasets\n",
    "df_total = pd.concat([df_reales_75, df_sinteticos_75], ignore_index=True)\n",
    "\n",
    "# 4. One-hot encoding para variables categóricas\n",
    "df_total = pd.get_dummies(df_total, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# 5. Eliminar columna de texto si existe\n",
    "if 'Evolucion Final' in df_total.columns:\n",
    "    df_total.drop(columns=['Evolucion Final'], inplace=True)\n",
    "\n",
    "# 6. Separar variables predictoras y variable objetivo\n",
    "X = df_total.drop(columns='target')\n",
    "y = df_total['target']\n",
    "\n",
    "# 7. Validación cruzada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 8. Resultados\n",
    "resultados = []\n",
    "\n",
    "# 9. MODELO - Arquitectura PROFUNDA (opción 2, la mejor anterior)\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Escalar\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=8, callbacks=[es], verbose=0)\n",
    "\n",
    "    # Predicción\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Evaluación\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# 10. Mostrar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c5d44",
   "metadata": {},
   "source": [
    "VERSION REPRODUCIBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b09f396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000196B13A9A20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.700000   0.680000  0.944444  0.790698  0.685185\n",
      "1  0.700000   0.680000  0.944444  0.790698  0.625000\n",
      "2  0.833333   0.809524  0.944444  0.871795  0.842593\n",
      "3  0.700000   0.750000  0.789474  0.769231  0.712919\n",
      "4  0.733333   0.761905  0.842105  0.800000  0.775120\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.7333     0.7363  0.8930  0.8045  0.7282\n",
      "std      0.0577     0.0560  0.0729  0.0393  0.0837\n",
      "min      0.7000     0.6800  0.7895  0.7692  0.6250\n",
      "25%      0.7000     0.6800  0.8421  0.7907  0.6852\n",
      "50%      0.7000     0.7500  0.9444  0.7907  0.7129\n",
      "75%      0.7333     0.7619  0.9444  0.8000  0.7751\n",
      "max      0.8333     0.8095  0.9444  0.8718  0.8426\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 0. Fijar semillas para reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 1. Cargar datasets\n",
    "df_reales = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sinteticos = pd.read_excel(\"datos_sinteticos_finales.xlsx\")\n",
    "\n",
    "# 2. Seleccionar 75 reales y 75 sintéticos\n",
    "df_reales_75 = df_reales.sample(n=75, random_state=SEED)\n",
    "df_sinteticos_75 = df_sinteticos.sample(n=75, random_state=SEED)\n",
    "\n",
    "# 3. Concatenar ambos datasets\n",
    "df_total = pd.concat([df_reales_75, df_sinteticos_75], ignore_index=True)\n",
    "\n",
    "# 4. One-hot encoding para variables categóricas\n",
    "df_total = pd.get_dummies(df_total, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# 5. Eliminar columna de texto si existe\n",
    "if 'Evolucion Final' in df_total.columns:\n",
    "    df_total.drop(columns=['Evolucion Final'], inplace=True)\n",
    "\n",
    "# 6. Separar variables predictoras y variable objetivo\n",
    "X = df_total.drop(columns='target')\n",
    "y = df_total['target']\n",
    "\n",
    "# 7. Validación cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# 8. Resultados por fold\n",
    "resultados = []\n",
    "\n",
    "# 9. Modelo: Arquitectura profunda (opción 2)\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=8, callbacks=[es], verbose=0)\n",
    "\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# 10. Mostrar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
