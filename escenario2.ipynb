{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ee3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.800000   0.800000  0.888889  0.842105  0.722222\n",
      "1  0.866667   0.818182  1.000000  0.900000  0.944444\n",
      "2  0.866667   0.888889  0.888889  0.888889  0.962963\n",
      "3  0.866667   0.888889  0.888889  0.888889  0.925926\n",
      "4  0.800000   0.857143  0.750000  0.800000  0.928571\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.8400     0.8506  0.8833  0.8640  0.8968\n",
      "std      0.0365     0.0406  0.0887  0.0422  0.0987\n",
      "min      0.8000     0.8000  0.7500  0.8000  0.7222\n",
      "25%      0.8000     0.8182  0.8889  0.8421  0.9259\n",
      "50%      0.8667     0.8571  0.8889  0.8889  0.9286\n",
      "75%      0.8667     0.8889  0.8889  0.8889  0.9444\n",
      "max      0.8667     0.8889  1.0000  0.9000  0.9630\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_excel(\"dataset_resultado_categorizado.xlsx\")\n",
    "\n",
    "# Crear variable binaria\n",
    "df['target'] = df['Evolucion Final'].apply(lambda x: 1 if x != 'Nada' else 0)\n",
    "\n",
    "# Imputar valores faltantes con la mediana\n",
    "df_imputado = df.copy()\n",
    "for col in df_imputado.select_dtypes(include=[np.number]).columns:\n",
    "    df_imputado[col] = df_imputado[col].fillna(df_imputado[col].median())\n",
    "\n",
    "# Codificar variables categóricas\n",
    "df_imputado = pd.get_dummies(df_imputado, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "df_imputado.drop(columns=['Evolucion Final'], inplace=True)\n",
    "\n",
    "# Separar X e y\n",
    "X = df_imputado.drop(columns='target')\n",
    "y = df_imputado['target']\n",
    "\n",
    "# Validación cruzada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "resultados = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=8, callbacks=[es], verbose=0)\n",
    "\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2e3bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000236562AD360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.733333   0.777778  0.777778  0.777778  0.722222\n",
      "1  0.866667   0.818182  1.000000  0.900000  1.000000\n",
      "2  0.800000   1.000000  0.666667  0.800000  0.851852\n",
      "3  0.866667   0.888889  0.888889  0.888889  0.944444\n",
      "4  0.800000   0.857143  0.750000  0.800000  0.928571\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1     auc\n",
      "count    5.0000     5.0000  5.0000  5.0000  5.0000\n",
      "mean     0.8133     0.8684  0.8167  0.8333  0.8894\n",
      "std      0.0558     0.0846  0.1297  0.0567  0.1074\n",
      "min      0.7333     0.7778  0.6667  0.7778  0.7222\n",
      "25%      0.8000     0.8182  0.7500  0.8000  0.8519\n",
      "50%      0.8000     0.8571  0.7778  0.8000  0.9286\n",
      "75%      0.8667     0.8889  0.8889  0.8889  0.9444\n",
      "max      0.8667     1.0000  1.0000  0.9000  1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ========================\n",
    "# Configuración Reproducible\n",
    "# ========================\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# ========================\n",
    "# Cargar y preparar el dataset\n",
    "# ========================\n",
    "df = pd.read_excel(\"dataset_resultado_categorizado.xlsx\")\n",
    "\n",
    "# Crear variable binaria para evolución\n",
    "df['target'] = df['Evolucion Final'].apply(lambda x: 1 if x != 'Nada' else 0)\n",
    "\n",
    "# Imputar valores faltantes con la mediana\n",
    "df_imputado = df.copy()\n",
    "for col in df_imputado.select_dtypes(include=[np.number]).columns:\n",
    "    df_imputado[col] = df_imputado[col].fillna(df_imputado[col].median())\n",
    "\n",
    "# Codificar variables categóricas\n",
    "df_imputado = pd.get_dummies(df_imputado, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# Eliminar columna de texto no necesaria\n",
    "df_imputado.drop(columns=['Evolucion Final'], inplace=True)\n",
    "\n",
    "# Separar X e y\n",
    "X = df_imputado.drop(columns='target')\n",
    "y = df_imputado['target']\n",
    "\n",
    "# ========================\n",
    "# Validación cruzada estratificada\n",
    "# ========================\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "resultados = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100, batch_size=8, callbacks=[es], verbose=0)\n",
    "\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# ========================\n",
    "# Mostrar resultados\n",
    "# ========================\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
