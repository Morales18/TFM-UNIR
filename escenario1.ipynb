{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c4cec61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Variable  Nulos  Porcentaje (%)\n",
      "43                     Prot24 h (g/24H)     21       28.000000\n",
      "84  Tiempo en alcanzar remisión (meses)     17       22.666667\n",
      "93                             VDI 24 m     16       21.333333\n",
      "77                        Respuesta 24m     16       21.333333\n",
      "49                           MPO título     15       20.000000\n",
      "..                                  ...    ...             ...\n",
      "91                               Muerte      0        0.000000\n",
      "90                             Diálisis      0        0.000000\n",
      "95                                 Edad      0        0.000000\n",
      "96                  Resultado renal cat      0        0.000000\n",
      "97                      Evolucion Final      0        0.000000\n",
      "\n",
      "[98 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_excel(\"dataset_resultado_categorizado.xlsx\")\n",
    "\n",
    "# Calcular resumen de nulos\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_percentage = (missing_summary / len(df)) * 100\n",
    "\n",
    "# Crear dataframe con el resumen\n",
    "missing_df = pd.DataFrame({\n",
    "    \"Variable\": missing_summary.index,\n",
    "    \"Nulos\": missing_summary.values,\n",
    "    \"Porcentaje (%)\": missing_percentage.values\n",
    "}).sort_values(by=\"Nulos\", ascending=False)\n",
    "\n",
    "# Mostrar resultado\n",
    "print(missing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a08591d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      62\n",
       "float64    33\n",
       "object      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carga del dataset (ajusta el nombre si es necesario)\n",
    "df = pd.read_excel(\"dataset_resultado_categorizado.xlsx\")\n",
    "\n",
    "# Mostramos tipos de datos\n",
    "df.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d36cb127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipo_vasculitis:\n",
      "Tipo_vasculitis\n",
      "MPO    47\n",
      "PR3    23\n",
      "NEG     5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tipo:\n",
      "Tipo\n",
      "PAM     35\n",
      "GPA     28\n",
      "EGPA    12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Evolucion Final:\n",
      "Evolucion Final\n",
      "Nada                   31\n",
      "Muerte                 17\n",
      "IRC                    16\n",
      "IRC, ERCA               7\n",
      "IRC, ERCA, Diálisis     4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ver columnas que no son numéricas\n",
    "df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in ['Tipo_vasculitis', 'Tipo', 'Evolucion Final']:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c8c846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia del DataFrame por seguridad\n",
    "df_modelo = df.copy()\n",
    "\n",
    "# One-hot encoding de variables categóricas\n",
    "df_modelo = pd.get_dummies(df_modelo, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# Codificación binaria del target\n",
    "df_modelo['target'] = df_modelo['Evolucion Final'].apply(lambda x: 0 if x == 'Nada' else 1)\n",
    "\n",
    "# Eliminamos la columna original del target\n",
    "df_modelo.drop(columns=['Evolucion Final'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2036cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar variables predictoras (X) y variable objetivo binaria (y)\n",
    "X = df_modelo.drop(columns='target')\n",
    "y = df_modelo['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bdbd15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (75, 99)\n",
      "y shape: (75,)\n",
      "y valores únicos: [1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"X shape: {X_scaled.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y valores únicos: {y.unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14652873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jorge Morales\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jorge Morales\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jorge Morales\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jorge Morales\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jorge Morales\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "   accuracy  precision  recall        f1  auc\n",
      "0  0.600000   0.600000     1.0  0.750000  0.5\n",
      "1  0.600000   0.600000     1.0  0.750000  0.5\n",
      "2  0.600000   0.600000     1.0  0.750000  0.5\n",
      "3  0.600000   0.600000     1.0  0.750000  0.5\n",
      "4  0.533333   0.533333     1.0  0.695652  0.5\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1  auc\n",
      "count    5.0000     5.0000     5.0  5.0000  5.0\n",
      "mean     0.5867     0.5867     1.0  0.7391  0.5\n",
      "std      0.0298     0.0298     0.0  0.0243  0.0\n",
      "min      0.5333     0.5333     1.0  0.6957  0.5\n",
      "25%      0.6000     0.6000     1.0  0.7500  0.5\n",
      "50%      0.6000     0.6000     1.0  0.7500  0.5\n",
      "75%      0.6000     0.6000     1.0  0.7500  0.5\n",
      "max      0.6000     0.6000     1.0  0.7500  0.5\n"
     ]
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. Cargar el dataset real con imputación parcial\n",
    "df = pd.read_excel(\"dataset_resultado_categorizado.xlsx\")\n",
    "\n",
    "# 2. Crear variable binaria como objetivo (0 = Nada, 1 = cualquier evolución negativa)\n",
    "df['target'] = df['Evolucion Final'].apply(lambda x: 1 if x != 'Nada' else 0)\n",
    "\n",
    "# 3. Codificar variables categóricas con one-hot encoding\n",
    "df_modelo = pd.get_dummies(df, columns=['Tipo_vasculitis', 'Tipo'], drop_first=True)\n",
    "\n",
    "# 4. Eliminar columna objetivo textual\n",
    "df_modelo.drop(columns=['Evolucion Final'], inplace=True)\n",
    "\n",
    "# 5. Separar variables independientes y dependiente\n",
    "X = df_modelo.drop(columns='target')\n",
    "y = df_modelo['target']\n",
    "\n",
    "# 6. Escalar variables numéricas\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 7. Validación cruzada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 8. Resultados a almacenar\n",
    "results = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1': [],\n",
    "    'auc': []\n",
    "}\n",
    "\n",
    "# 9. Entrenamiento del modelo en cada fold\n",
    "for train_idx, val_idx in skf.split(X_scaled, y):\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_val).ravel()\n",
    "    y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # 10. Evaluación\n",
    "    results['accuracy'].append(accuracy_score(y_val, y_pred_label))\n",
    "    results['precision'].append(precision_score(y_val, y_pred_label, zero_division=0))\n",
    "    results['recall'].append(recall_score(y_val, y_pred_label))\n",
    "    results['f1'].append(f1_score(y_val, y_pred_label))\n",
    "    results['auc'].append(roc_auc_score(y_val, y_pred))\n",
    "\n",
    "# 11. Visualizar resultados en forma de tabla\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(results_df.describe().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "791970e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "   accuracy  precision  recall        f1  auc\n",
      "0  0.600000   0.600000     1.0  0.750000  0.5\n",
      "1  0.600000   0.600000     1.0  0.750000  0.5\n",
      "2  0.600000   0.600000     1.0  0.750000  0.5\n",
      "3  0.600000   0.600000     1.0  0.750000  0.5\n",
      "4  0.533333   0.533333     1.0  0.695652  0.5\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision  recall      f1  auc\n",
      "count    5.0000     5.0000     5.0  5.0000  5.0\n",
      "mean     0.5867     0.5867     1.0  0.7391  0.5\n",
      "std      0.0298     0.0298     0.0  0.0243  0.0\n",
      "min      0.5333     0.5333     1.0  0.6957  0.5\n",
      "25%      0.6000     0.6000     1.0  0.7500  0.5\n",
      "50%      0.6000     0.6000     1.0  0.7500  0.5\n",
      "75%      0.6000     0.6000     1.0  0.7500  0.5\n",
      "max      0.6000     0.6000     1.0  0.7500  0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Supone que ya tienes definidos X y y con tus datos reales (escenario 1)\n",
    "\n",
    "resultados = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in kfold.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Normalización\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping para evitar sobreajuste\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    # Entrenamiento\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100,\n",
    "              batch_size=8,\n",
    "              callbacks=[es],\n",
    "              verbose=0,\n",
    "              )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6513b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "   accuracy  precision  recall        f1  auc\n",
      "0  0.600000   0.600000     1.0  0.750000  0.5\n",
      "1  0.600000   0.600000     1.0  0.750000  0.5\n",
      "2  0.400000   0.000000     0.0  0.000000  0.5\n",
      "3  0.400000   0.000000     0.0  0.000000  0.5\n",
      "4  0.533333   0.533333     1.0  0.695652  0.5\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision    recall        f1  auc\n",
      "count  5.000000   5.000000  5.000000  5.000000  5.0\n",
      "mean   0.506667   0.346667  0.600000  0.439130  0.5\n",
      "std    0.101105   0.317630  0.547723  0.401483  0.0\n",
      "min    0.400000   0.000000  0.000000  0.000000  0.5\n",
      "25%    0.400000   0.000000  0.000000  0.000000  0.5\n",
      "50%    0.533333   0.533333  1.000000  0.695652  0.5\n",
      "75%    0.600000   0.600000  1.000000  0.750000  0.5\n",
      "max    0.600000   0.600000  1.000000  0.750000  0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Inicializar listas para almacenar métricas\n",
    "resultados = []\n",
    "\n",
    "# Configurar validación cruzada\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X, y):\n",
    "    # División de datos\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Escalado de características\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Cálculo de pesos de clase\n",
    "    y_train_array = np.array(y_train)\n",
    "    pesos = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_array), y=y_train_array)\n",
    "    class_weights = dict(zip(np.unique(y_train_array), pesos))\n",
    "\n",
    "    # Construcción del modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # EarlyStopping\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Entrenamiento\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100,\n",
    "              batch_size=8,\n",
    "              callbacks=[es],\n",
    "              verbose=0,\n",
    "              class_weight=class_weights)\n",
    "\n",
    "    # Evaluación\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198c53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "   accuracy  precision  recall    f1  auc\n",
      "0  0.600000        0.6     1.0  0.75  0.5\n",
      "1  0.400000        0.0     0.0  0.00  0.5\n",
      "2  0.400000        0.0     0.0  0.00  0.5\n",
      "3  0.400000        0.0     0.0  0.00  0.5\n",
      "4  0.466667        0.0     0.0  0.00  0.5\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision    recall       f1  auc\n",
      "count  5.000000   5.000000  5.000000  5.00000  5.0\n",
      "mean   0.453333   0.120000  0.200000  0.15000  0.5\n",
      "std    0.086923   0.268328  0.447214  0.33541  0.0\n",
      "min    0.400000   0.000000  0.000000  0.00000  0.5\n",
      "25%    0.400000   0.000000  0.000000  0.00000  0.5\n",
      "50%    0.400000   0.000000  0.000000  0.00000  0.5\n",
      "75%    0.466667   0.000000  0.000000  0.00000  0.5\n",
      "max    0.600000   0.600000  1.000000  0.75000  0.5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "resultados = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Normalizar\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Pesos de clase\n",
    "    pesos = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = dict(zip(np.unique(y_train), pesos))\n",
    "\n",
    "    # Arquitectura muy simple\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1],)),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Entrenamiento\n",
    "    model.fit(X_train_scaled, y_train,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              epochs=100,\n",
    "              batch_size=4,\n",
    "              verbose=0,\n",
    "              class_weight=class_weights,\n",
    "              callbacks=[es])\n",
    "\n",
    "    # Evaluación\n",
    "    y_pred_probs = model.predict(X_val_scaled).ravel()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    resultados.append({\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_val, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_val, y_pred_probs)\n",
    "    })\n",
    "\n",
    "# Mostrar métricas\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(df_resultados)\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df_resultados.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa6f9f1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
