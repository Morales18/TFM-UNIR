{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96df371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entrenando Escenario 5a (75 sintéticos) ===\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002681B10E7A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Accuracy:  0.7333 ± 0.0699\n",
      "Precision: 0.7508 ± 0.0596\n",
      "Recall:    0.8737 ± 0.0537\n",
      "F1-score:  0.8064 ± 0.0487\n",
      "AUC:       0.7416 ± 0.1037\n",
      "\n",
      "=== Entrenando Escenario 5b (150 sintéticos) ===\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002681E4315A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Accuracy:  0.7022 ± 0.0301\n",
      "Precision: 0.7354 ± 0.0401\n",
      "Recall:    0.8572 ± 0.0397\n",
      "F1-score:  0.7901 ± 0.0186\n",
      "AUC:       0.6636 ± 0.0898\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# -------------------------\n",
    "# 1. Controlar aleatoriedad\n",
    "# -------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Cargar datasets\n",
    "# -------------------------\n",
    "df_real = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sint = pd.read_excel(\"datos_sinteticos_mahalanobis.xlsx\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. Codificación categórica\n",
    "# -------------------------\n",
    "# Unificamos para codificar igual ambos\n",
    "df_real[\"es_sintetico\"] = 0\n",
    "df_sint[\"es_sintetico\"] = 1\n",
    "df_total = pd.concat([df_real, df_sint], ignore_index=True)\n",
    "\n",
    "# One-hot encoding de variables categóricas\n",
    "df_total = pd.get_dummies(df_total, columns=[\"Tipo\", \"Tipo_vasculitis\"], drop_first=True)\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "cols_a_eliminar = [\"Evolucion Final\", \"es_sintetico\"]\n",
    "df_total = df_total.drop(columns=[col for col in cols_a_eliminar if col in df_total.columns])\n",
    "\n",
    "# -------------------------\n",
    "# 4. Generar escenarios\n",
    "# -------------------------\n",
    "# Separar nuevamente\n",
    "df_reales = df_total[df_total.index < len(df_real)]\n",
    "df_sint = df_total[df_total.index >= len(df_real)]\n",
    "\n",
    "df_5a = pd.concat([df_reales, df_sint.sample(n=75, random_state=SEED)], ignore_index=True)\n",
    "df_5b = pd.concat([df_reales, df_sint.sample(n=150, random_state=SEED)], ignore_index=True)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Función de entrenamiento\n",
    "# -------------------------\n",
    "def entrenar_modelo(df, nombre=\"Modelo\"):\n",
    "    print(f\"\\n=== Entrenando {nombre} ===\")\n",
    "\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "    accs, precs, recalls, f1s, aucs = [], [], [], [], []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_scaled, y):\n",
    "        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = Sequential([\n",
    "            Input(shape=(X.shape[1],)),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        model.fit(X_train, y_train,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  epochs=100, batch_size=16,\n",
    "                  callbacks=[es], verbose=0)\n",
    "\n",
    "        y_pred_probs = model.predict(X_val).ravel()\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        accs.append(accuracy_score(y_val, y_pred))\n",
    "        precs.append(precision_score(y_val, y_pred, zero_division=0))\n",
    "        recalls.append(recall_score(y_val, y_pred, zero_division=0))\n",
    "        f1s.append(f1_score(y_val, y_pred, zero_division=0))\n",
    "        aucs.append(roc_auc_score(y_val, y_pred_probs))\n",
    "\n",
    "    print(f\"Accuracy:  {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "    print(f\"Precision: {np.mean(precs):.4f} ± {np.std(precs):.4f}\")\n",
    "    print(f\"Recall:    {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n",
    "    print(f\"F1-score:  {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "    print(f\"AUC:       {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 6. Ejecutar ambos modelos\n",
    "# -------------------------\n",
    "entrenar_modelo(df_5a, nombre=\"Escenario 5a (75 sintéticos)\")\n",
    "entrenar_modelo(df_5b, nombre=\"Escenario 5b (150 sintéticos)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d9d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\n",
      "=== Resultados por fold - Escenario 5a (75 sintéticos) ===\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  1.000000   1.000000  1.000000  1.000000  1.000000\n",
      "1  0.933333   0.947368  0.947368  0.947368  0.990431\n",
      "2  0.866667   0.826087  1.000000  0.904762  0.980861\n",
      "3  0.933333   0.947368  0.947368  0.947368  0.995215\n",
      "4  0.800000   0.842105  0.842105  0.842105  0.933014\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision    recall        f1       auc\n",
      "count  5.000000   5.000000  5.000000  5.000000  5.000000\n",
      "mean   0.906667   0.912586  0.947368  0.928321  0.979904\n",
      "std    0.076012   0.075017  0.064460  0.058847  0.027151\n",
      "min    0.800000   0.826087  0.842105  0.842105  0.933014\n",
      "25%    0.866667   0.842105  0.947368  0.904762  0.980861\n",
      "50%    0.933333   0.947368  0.947368  0.947368  0.990431\n",
      "75%    0.933333   0.947368  1.000000  0.947368  0.995215\n",
      "max    1.000000   1.000000  1.000000  1.000000  1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ut07137\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\n",
      "=== Resultados por fold - Escenario 5b (150 sintéticos) ===\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.911111   0.906250  0.966667  0.935484  0.982222\n",
      "1  0.977778   0.967742  1.000000  0.983607  1.000000\n",
      "2  0.977778   0.966667  1.000000  0.983051  1.000000\n",
      "3  0.911111   0.903226  0.965517  0.933333  0.989224\n",
      "4  1.000000   1.000000  1.000000  1.000000  1.000000\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision    recall        f1       auc\n",
      "count  5.000000   5.000000  5.000000  5.000000  5.000000\n",
      "mean   0.955556   0.948777  0.986437  0.967095  0.994289\n",
      "std    0.041574   0.042388  0.018577  0.030615  0.008202\n",
      "min    0.911111   0.903226  0.965517  0.933333  0.982222\n",
      "25%    0.911111   0.906250  0.966667  0.935484  0.989224\n",
      "50%    0.977778   0.966667  1.000000  0.983051  1.000000\n",
      "75%    0.977778   0.967742  1.000000  0.983607  1.000000\n",
      "max    1.000000   1.000000  1.000000  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cargar datasets\n",
    "df_real = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sint = pd.read_excel(\"datos_sinteticos_mahalanobis.xlsx\")\n",
    "\n",
    "# Crear los escenarios\n",
    "df_5a = pd.concat([df_real, df_sint.sample(n=75, random_state=42)], ignore_index=True)\n",
    "df_5b = pd.concat([df_real, df_sint.sample(n=150, random_state=42)], ignore_index=True)\n",
    "\n",
    "def preparar_dataset(df):\n",
    "    df = df.drop(columns=[\"Evolución Final\", \"IRC\", \"ERCA\", \"Muerte\", \"Dialisis\"], errors='ignore')\n",
    "    df = pd.get_dummies(df)\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "    y = df[\"target\"]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "def entrenar_modelo(X, y, nombre_escenario):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    resultados = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, activation='relu', input_dim=X.shape[1]))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy')\n",
    "\n",
    "        early_stop = EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss', verbose=0)\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=16, callbacks=[early_stop], verbose=0)\n",
    "\n",
    "        y_pred_prob = model.predict(X_val).ravel()\n",
    "        y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "        resultados.append({\n",
    "            \"accuracy\": accuracy_score(y_val, y_pred),\n",
    "            \"precision\": precision_score(y_val, y_pred),\n",
    "            \"recall\": recall_score(y_val, y_pred),\n",
    "            \"f1\": f1_score(y_val, y_pred),\n",
    "            \"auc\": roc_auc_score(y_val, y_pred_prob)\n",
    "        })\n",
    "\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    print(f\"\\n=== Resultados por fold - {nombre_escenario} ===\")\n",
    "    print(df_resultados)\n",
    "    print(f\"\\nResumen estadístico:\\n{df_resultados.describe()}\")\n",
    "\n",
    "# Preparar y entrenar ambos escenarios\n",
    "X_5a, y_5a = preparar_dataset(df_5a)\n",
    "X_5b, y_5b = preparar_dataset(df_5b)\n",
    "\n",
    "entrenar_modelo(X_5a, y_5a, \"Escenario 5a (75 sintéticos)\")\n",
    "entrenar_modelo(X_5b, y_5b, \"Escenario 5b (150 sintéticos)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97e91a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados por fold - Escenario 5a (75 sintéticos) ===\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.800000   0.782609  0.947368  0.857143  0.808612\n",
      "1  0.800000   0.809524  0.894737  0.850000  0.885167\n",
      "2  0.666667   0.680000  0.894737  0.772727  0.602871\n",
      "3  0.700000   0.727273  0.842105  0.780488  0.655502\n",
      "4  0.666667   0.714286  0.789474  0.750000  0.765550\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision    recall        f1       auc\n",
      "count  5.000000   5.000000  5.000000  5.000000  5.000000\n",
      "mean   0.726667   0.742738  0.873684  0.802072  0.743541\n",
      "std    0.068313   0.052523  0.060009  0.048395  0.114363\n",
      "min    0.666667   0.680000  0.789474  0.750000  0.602871\n",
      "25%    0.666667   0.714286  0.842105  0.772727  0.655502\n",
      "50%    0.700000   0.727273  0.894737  0.780488  0.765550\n",
      "75%    0.800000   0.782609  0.894737  0.850000  0.808612\n",
      "max    0.800000   0.809524  0.947368  0.857143  0.885167\n",
      "\n",
      "=== Resultados por fold - Escenario 5b (150 sintéticos) ===\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "   accuracy  precision    recall        f1       auc\n",
      "0  0.711111   0.729730  0.900000  0.805970  0.593333\n",
      "1  0.755556   0.806452  0.833333  0.819672  0.744444\n",
      "2  0.733333   0.774194  0.827586  0.800000  0.754310\n",
      "3  0.666667   0.684211  0.896552  0.776119  0.530172\n",
      "4  0.688889   0.714286  0.862069  0.781250  0.706897\n",
      "\n",
      "Resumen estadístico:\n",
      "       accuracy  precision    recall        f1       auc\n",
      "count  5.000000   5.000000  5.000000  5.000000  5.000000\n",
      "mean   0.711111   0.741774  0.863908  0.796602  0.665831\n",
      "std    0.035136   0.048602  0.034006  0.017936  0.099189\n",
      "min    0.666667   0.684211  0.827586  0.776119  0.530172\n",
      "25%    0.688889   0.714286  0.833333  0.781250  0.593333\n",
      "50%    0.711111   0.729730  0.862069  0.800000  0.706897\n",
      "75%    0.733333   0.774194  0.896552  0.805970  0.744444\n",
      "max    0.755556   0.806452  0.900000  0.819672  0.754310\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# -------------------------\n",
    "# 1. Controlar aleatoriedad\n",
    "# -------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Cargar datasets\n",
    "# -------------------------\n",
    "df_real = pd.read_excel(\"dataset_reales_imputados.xlsx\")\n",
    "df_sint = pd.read_excel(\"datos_sinteticos_mahalanobis.xlsx\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. Codificación categórica\n",
    "# -------------------------\n",
    "df_real[\"es_sintetico\"] = 0\n",
    "df_sint[\"es_sintetico\"] = 1\n",
    "df_total = pd.concat([df_real, df_sint], ignore_index=True)\n",
    "\n",
    "df_total = pd.get_dummies(df_total, columns=[\"Tipo\", \"Tipo_vasculitis\"], drop_first=True)\n",
    "\n",
    "cols_a_eliminar = [\"Evolucion Final\", \"es_sintetico\"]\n",
    "df_total = df_total.drop(columns=[col for col in cols_a_eliminar if col in df_total.columns])\n",
    "\n",
    "# -------------------------\n",
    "# 4. Generar escenarios\n",
    "# -------------------------\n",
    "df_reales = df_total[df_total.index < len(df_real)]\n",
    "df_sint = df_total[df_total.index >= len(df_real)]\n",
    "\n",
    "df_5a = pd.concat([df_reales, df_sint.sample(n=75, random_state=SEED)], ignore_index=True)\n",
    "df_5b = pd.concat([df_reales, df_sint.sample(n=150, random_state=SEED)], ignore_index=True)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Función de entrenamiento\n",
    "# -------------------------\n",
    "def entrenar_modelo(df, nombre=\"Modelo\"):\n",
    "    print(f\"\\n=== Resultados por fold - {nombre} ===\")\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        model = Sequential([\n",
    "            Input(shape=(X.shape[1],)),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy')\n",
    "        es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                  epochs=100, batch_size=16, callbacks=[es], verbose=0)\n",
    "\n",
    "        y_pred_probs = model.predict(X_val).ravel()\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        resultados.append({\n",
    "            \"accuracy\": accuracy_score(y_val, y_pred),\n",
    "            \"precision\": precision_score(y_val, y_pred, zero_division=0),\n",
    "            \"recall\": recall_score(y_val, y_pred, zero_division=0),\n",
    "            \"f1\": f1_score(y_val, y_pred, zero_division=0),\n",
    "            \"auc\": roc_auc_score(y_val, y_pred_probs)\n",
    "        })\n",
    "\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    print(df_resultados)\n",
    "    print(\"\\nResumen estadístico:\")\n",
    "    print(df_resultados.describe())\n",
    "\n",
    "# -------------------------\n",
    "# 6. Ejecutar ambos modelos\n",
    "# -------------------------\n",
    "entrenar_modelo(df_5a, nombre=\"Escenario 5a (75 sintéticos)\")\n",
    "entrenar_modelo(df_5b, nombre=\"Escenario 5b (150 sintéticos)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
